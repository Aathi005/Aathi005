import torch
from transformers import BertTokenizer, BertForSequenceClassification, AdamW
from torch.utils.data import TensorDataset, DataLoader
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score

texts = ["I love this movie!", "This is a terrible film.", "The acting was great.", "A really bad experience."]
labels = [1, 0, 1, 0]  
tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')
encoded_data = tokenizer(texts, padding=True, truncation=True, return_tensors='pt')
input_ids = encoded_data['input_ids']
attention_mask = encoded_data['attention_mask']
labels_tensor = torch.tensor(labels)

train_inputs, test_inputs, train_labels, test_labels, train_masks, test_masks = 
      train_test_split (input_ids, labels_tensor, attention_mask, random_state=42, test_size=0.25)
train_dataset = TensorDataset(train_inputs, train_masks, train_labels)
test_dataset = TensorDataset(test_inputs, test_masks, test_labels)
batch_size = 2

train_dataloader = DataLoader(train_dataset, shuffle=True, batch_size=batch_size)
test_dataloader = DataLoader(test_dataset, shuffle=False, batch_size=batch_size)
model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=2)
optimizer = AdamW(model.parameters(), lr=2e-5)
epochs = 3

for epoch in range(epochs):
    model.train()
    total_loss = 0
    for batch in train_dataloader:
        input_ids, attention_mask, labels = batch
        optimizer.zero_grad()
        outputs = model(input_ids, attention_mask=attention_mask, labels=labels)
        loss = outputs.loss
        loss.backward()
        optimizer.step()
        total_loss += loss.item()
    avg_loss = total_loss / len(train_dataloader)
    print(f"Epoch {epoch + 1}/{epochs}, Average Loss: {avg_loss:.4f}")
model.eval()
predictions = []
true_labels = []

for batch in test_dataloader:
    input_ids, attention_mask, labels = batch
    true_labels.extend(labels.tolist())
    with torch.no_grad():
        outputs = model(input_ids, attention_mask=attention_mask)
        logits = outputs.logits
    preds = torch.argmax(logits, dim=1).tolist()
    predictions.extend(preds)
accuracy = accuracy_score(true_labels, predictions)
print(f"Accuracy: {accuracy * 100:.2f}%")



Output: 
Epoch 1/3, Loss: 0.5642
Epoch 2/3, Loss: 0.3123
Epoch 3/3, Loss: 0.2107
Accuracy: 100.00%


